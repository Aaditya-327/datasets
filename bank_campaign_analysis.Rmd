---
title: "Bank Campaign Analysis"
author: "Kathirmani Sukumar"
date: "September 5, 2017"
output: html_document
---

```{r setup, include=FALSE, message=FALSE, warning=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

### Load data
```{r, message=FALSE, warning=FALSE}
library(dplyr)
library(ggplot2)
library(reshape)
library(knitr)
bank = read.csv('c:/Users/Kathirmani/Desktop/manipal_eda/bank/bank-full.csv', sep = ';')
dim(bank)

```

## EDA Process
- Check for number of rows and columns
- Understand what each row is for
- Calculate the percentage of nulls in each column
- Missing value treatment
- Identify the type of each column
  - Groups, Metrics, Dates, Text, Location
- Derive new columns
  - Date
    - Day, month, year, day of week, week of the year, quarter etc
  - Numerical column
    - Bins (Age group from age, financial status from bank balance etc)
    - Thresholds (Centuries, fifties from runs etc)
  - And classifiy the new derived columns 
  - For each dimension column
    - Group by and calculate the count and percentage
    - See if any sub group has more than 80%. If so think if we should remove that column from data
  - For each numerical column
    - Draw histogram
      - Look for distribution
      - Skewness
      - Outliers
    - Draw box plot
      - Identify outliers
  - Pick one dimension and one numerical column
    - Group by dimension and take average of the numerical column
    - Compute t-test or ANNOVA
  - Pick two dimensions column
    - Crosstab analysis
    - Chi-square test for statistical validation
  - Pick two numerical columns
    - Plot scatter plot
    - Look at trending, outliers and visual grouping
  - Multivariate analysis

### Data availability
```{r, message=FALSE, warning=FALSE}
num.na = colSums(!is.na(bank))*100/nrow(bank)
num.na
```

### Frequency distribution of each dimension column
```{r, message=FALSE, warning=FALSE}
group_name = 'marital'
education_counts = bank %>% group_by(group=get(group_name)) %>% summarise(group_percs=n()*100/nrow(bank))
ggplot(education_counts,aes(x=group,y=group_percs))+ geom_bar(stat='identity') + coord_flip()
```

## Frequency distribution of each numerical column
### Box plot
- To identify outliers
- To look at quartiles
```{r, message=FALSE, warning=FALSE}
boxplot(bank$age)
```

```{r, message=FALSE, warning=FALSE}
# sum(bank$age>70.5) / nrow(bank) * 100

rows_above_70 = filter(bank, age>70.5)
age_outlier_perc = nrow(rows_above_70) / nrow(bank) * 100
age_outlier_perc
```

### Histogram
- To get an idean about underlying distribution
- To check if data is skewed
- To check for standard deviation/Variation
- To detect outliers

```{r, message=FALSE, warning=FALSE}
hist(bank$balance)
```
```{r, message=FALSE, warning=FALSE}
summary(bank$balance)
quantile(bank$balance)
```
### Box plot
- To identify outliers
- To look at quartiles
```{r, message=FALSE, warning=FALSE}
boxplot(bank$balance)
iqr = 1428 - 72
outlier_upper_range = 1428 + 1.5 * iqr
outlier_perc = sum(bank$balance > outlier_upper_range) / nrow(bank) * 100
outlier_perc
```

### No. of campaigns across different months
```{r, message=FALSE, warning=FALSE}
f= bank %>% group_by(month) %>% summarise(s=sum(campaign)) %>% arrange(-s)
head(f,2)

f= bank %>% group_by(month) %>% summarise(count=n()/nrow(bank)*100) %>% arrange(-count)
kable(f)
```
### Avg balance across job category
```{r, message=FALSE, warning=FALSE}
job_balance= bank %>% group_by(job) %>% summarise(avg_bal=mean(balance), count=n()) %>% arrange(-count)
ggplot(job_balance,aes(x=job,y=count,fill=-avg_bal))+geom_bar(stat="identity") + coord_flip()
```


### Response rate by job category
```{r, message=FALSE, warning=FALSE}
bank=mutate(bank,responded=if_else(y=='yes',1,0))
sum(bank$responded)

response_job = bank %>% group_by(job) %>% summarise( response_rate=mean(responded)*100) %>% arrange(-response_rate)
kable(response_job)
```

```{r, message=FALSE, warning=FALSE}
summary = table(bank$job, bank$marital)

# 1. Convert summary to data frame
summary = as.data.frame(summary)

# 2. Rename columns
names(summary) = c('job', 'marital', 'Freq')

# 3. Pass it to ggplot and use geom_tile() to get heatmap
ggplot(summary, aes(x=marital, y=job, fill=Freq)) + geom_tile() + scale_fill_gradient(low="white", high="red")

```

